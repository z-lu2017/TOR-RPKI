# TOR-RPKI

This project simulates TOR's guard relay selection process using our discount and matching selection algorithms. Please refer to the paper *RPKI-Based Location-Unaware Tor Guard Relay Selection Algorithms* for detail. The [modified Tor source code](https://github.com/z-lu2017/tor-modified) and [customized tornettools](https://github.com/z-lu2017/tornettools_custom) can be found in their separate repos.

## Description

This python simulator simultates TORâ€™s guard relay selection process. The simulator selects a guard relay based on the specified method (discount or matching) and creates client objects to mimic the relay selection process in the actual TOR network. The simulator also monitors the network load and performs dyanimc load balancing in the simulation. For matching algorithm, the updated relay weights are computed using linear optimization. See the paper for detail.

## Getting Started

### Dependencies

* [pyasn](https://github.com/hadiasghari/pyasn).
* [requests](https://pypi.org/project/requests/).
* [pytz](https://pypi.org/project/pytz/).
* [pandas](https://pandas.pydata.org/docs/getting_started/install.html).
* [scipy](https://pypi.org/project/scipy/).
* [matplotlib](https://matplotlib.org/stable/install/index.html).
* [PySCIPOpt](https://github.com/scipopt/PySCIPOpt).
* [lxml](https://pypi.org/project/lxml/).
* [bs4](https://pypi.org/project/beautifulsoup4/).

### Data and sources: All data can be found [here](https://torstudy.cs.virginia.edu/). If you prefer to download the data yourself, all data links can be found in the detailed description. Make sure to follow the directory structure. Be aware, raw data total size is more than 180 GB!!!
* Consensuses data:[Tor Metrics](https://metrics.torproject.org/collector.html). Extract **archive.zip** to root directory, it will create a folder named **archive**. 
* Routing data: [RouteViews](https://archive.routeviews.org/). Extract **routeviews.zip**  to root directory, it will create a folder named **routeviews**.
* Route Origin Authorization (ROAs): [RIPE_RPKI_archive](https://ftp.ripe.net/rpki/). Extract **ROAs.zip** and **mergedROAs.zip** to root directory, it will create two folders named **ROAs** and **mergedROAs**. Can also run ```python3 getROA.py``` to download ROA data from 2021-01-01 to 2024-05-31 directly and it will create a folder named **ROAs** for the raw ROAs and a folder named **mergedROAs** in the root directory. 
* Route Origin Validation (ROVs):
	* [ROV monitor](https://rov.rpki.net/): Originally proposed by [Reuter et al.](https://doi.org/10.1145/3211852.3211856). This list is compiled from parsing a static page from ROV monitor on 2024-05. 
	* [MANRS](https://github.com/CAIDA/MANRS_Data_Analysis): Measurement produced by [Du et al.](https://doi.org/10.1145/3517745.3561419). Two lists are compiled. **manrs-rov-high.txt** and **manrs-rov-low.txt** are used.
	* [RoVista](https://rovista.netsecurelab.org): Measurement performed by [Li et al.](https://dl.acm.org/doi/10.1145/3618257.3624806). **rovista.txt** is obtained from their published data.
	* [Routeservers](https://sit4.me/rpki): Measurement performed by [Hlavacek et al.](https://dl.acm.org/doi/10.5555/3620237.3620508). **protected.txt** is obtained from the source code.
* Other data:
	* [Inferred AS to Organization Mapping Dataset](https://www.caida.org/catalog/datasets/as-organizations/): **20240401.as-org2info.txt** is used.
	* [pyasn IP2ASN](https://github.com/hadiasghari/pyasn): **ipasn_2024-07-12.dat** is used.
	* Intermediate data: The link above also includes **archive_pickles.zip** and **processed.zip**, which are two intermediate data generated by data preprocessing. If you do not download those two folders, create two empty folders with the same name under root directory.

### Data processing:
Data processing is built into the simulation and each time intermediate results are stored in folder archive_pickles and processed. This is necessary since different simulations uses different client/relay objects. 

For artifact evaluation, only the raw data for 05/01/2024 is included to simplify the data processing step and save space. **(The total size for all raw data is at least 150 GB.)** Run ```python3 preprocess.py``` will process the data for 05/01/2024. The process will take approximately 10 min.

Measurement for ROA coverage for all ipv4/ipv6 relays and/or guard relays can be performed by running ```python3 graph_multi_months_roa.py [guards_only] [v4_or_v6]```. The first parameter is whether to plot for guards only and the second parameter is whether for v4 relays (y) or v6 relays(n). For example, ```python3 graph_multi_months_roa.py y y``` will produce the roa measurement for guards only for ipv4 relays only. The graphs produced are named "AllRelaysROACoverage_v4/v6.png" and "GuardOnlyROACoverage_v4/v6.png".


### Simulation

* To run the simulation: go to folder sim_roa_rov_L2 and execute

```
python3 sim_discount.py 
```

or 

```
python3 sim_matching.py
```

or

```
python3 matching_select.py
```

## Output
*sim_discount.py* runs two functions *run_sim()* and *sim_load()*. *run_sim()* simulates the discount selection algorithm on 1 million clients and outputs file *output-discount.csv* with the format date/discount/roa_coverage_before/roa_coverage_after. *sim_load()* simulates the relationship between load factor and discount factor and outputs two files *output-discount-load.csv* and *output-discount-load-optimal.csv*. *output-discount-load.csv* outputs the various load utilization under various combination of discount and load factor and is in the format date/discount/load/utilizations. *output-discount-load-optimal.csv* reports the best combo (aka kinks in the graphs) in the format date/discount/load. Either function can be run separately and both use the default date range from 2021-01-01 to 2024-05-31. The approximate runtime is 1 hour per datapoint/month.

*sim_matching.py* runs the matching selection algorithm on 1 million clients using various ROV source and outputs file *output-matching-202405.csv* with the format date/ROV_data/matched_before/matched_after. The default date used is May 2024. The approximate runtime will be 6 hours total, among which 2 hours is spent on client generation.

*matching_select.py* is the version running matching selection algorithm with churn. The default *matching_select.py* generates 1 million clients using geographic distribution from Tor Metrics and stores the client objects in the clients_daily folder. **The clients objects may be up to 2GB per day.** It is recommended to download our intermediate clients objects directly, then run *matching_select_new.py* and *matching_select_plain.py* to skip the client generation step. *matching_select_plain.py* is the version that performs matching without considering churn and uses the same client distribution from stored clients objects. For artifact evaluation, only 1 week of daily clients objects are stored to save space. The approximate runtime is 2 hours for *matching_select* and 1 hour for *matching_select_new* and *matching_select_plain* per day/data point. **However, the runtime for matching_select will increase as the clients objects are being updated daily, which may take up to 18 hours per datapoint. For artifact evaluation using our intermediate data running matching_select_plain and matching_select_new, the process should finish within 48 hours.** The outputs are stored in csv files labelled by *output-matching- + version +date* (e.g., output-matching-plain2024-01-02-00.csv). One output per day is produced. This is to prevent accidental crashes due to the long runtime and can be optimized accordingly. For artifact evaluation, intermediate results are provided for plotting.

## Plotting
All functions related to plotting simulation results are in the file *plot.py*. Make sure either use the output files from running the simulation or download our intermediate results. **Make sure plotting data exists before running the script**. The plotting for data measurement is in file *graph_multi_months_roa.py*.

## Shadow simulation
Shadow simulation using [tornettools](https://github.com/shadow/tornettools). The paper simulates 10% of the Tor network using Shadow version 3.2.0, and it will take more than 430 GB of memory for simulations on a 10% scale. The tornettools is customized to sample relays and clients using daily geographic distribution. ```generate.sh``` produces 10 networks of the scale 10% with random clients that matches our desired ROA/ROV distribution and are used as baseline. These 10 networks are copied to create folders for discount and matching, respectively. For each run, all algorithms are run on the same network to maintain a consistent basis so that the results are comparable. To run each simulation, put the corresponding precompiled executable (located at /home/ubuntu named tor-vanilla, tor-discount, tor-matching) in /home/ubuntu/.local/bin with name **tor** and run ```tornettools simulate tornet-0.1-$run```(replace the variable run with the folder name (e.g. discount1)). This step is also automated in the shell script *generate.sh*. Simulations takes up to 48 hours depending on hardware. 

For matching simulation, a set of relay names, prefixes and prefix counts are preloaded at /home/ubuntu/TOR-RPKI/sim_roa_rov_L2. Additional required files are stored at /usr/local/share/tor/:
* All files need to be put in folder /user/local/share/tor
* ROA database: The file used to check ROA. Original data from mergedROAs folder. In the VM, file 20240501.csv is used.
* ROV database: The file used to check ROV. Original data from any of the source listed on github. In the VM, ASNwROV.csv is used.
* Routeview data: The routeview file matching the data from the ROA database. Original data from routeviews folder. In the VM, file routeviews-rv2-20240501-1000.pfx2as is used.
It is important that data files match, i.e. the ROA database and the routeview data are close in date.

To simplify the artifact evaluation process and save resources, we suggest the reviewers to use scale 0.5% instead of 10% (roughly 36 relays and 3762 clients), which can be done with 16 GB of memory and less than 24 hours.

To see the results, run ```./aggregate.sh```. The aggregate script finds all data from all runs (search by filename with keyword "matching", "discount", "vanilla") and computes the mean for the selected measurements. Then run ```./graph.sh``` to parse all three categories and plot them against each other. The results will be in the folder named out.

## License

This project is licensed under the MIT License - see the LICENSE.md file for details

## Acknowledgments

* Our modified Tor source code is based on Tor version 0.4.8.7. The original Tor code can be found [here](https://git.torproject.org/tor.git)
* We modified tornettools to custom sample clients. The original tornettools code can be found [here](https://github.com/shadow/tornettools)
